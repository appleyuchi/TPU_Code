{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tpu_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vCjaBsCf9hr",
        "colab_type": "code",
        "outputId": "d404b423-f376-4ba3-c813-08c4755a2363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "\"\"\"在TPU运行时下测试有没有分配TPU计算资源\"\"\"\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.84.68.146:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 12130226390408489541),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5320787299609403774),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 9901116907118024406),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14271113716304435466),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17747454170824028722),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7990472732005410125),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17902030244935202217),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16771999600873480523),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11717095653002454467),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10334245990358205316),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14608019963017080513),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13158601318287340315)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXXoAcmIix6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"在CPU、GPU和TPU运行时状态下测试运行时间\"\"\"\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "tf.reset_default_graph()\n",
        "img = np.random.randn(128, 256, 256, 3).astype(np.float32)\n",
        "w = np.random.randn(5, 5, 3, 256).astype(np.float32)\n",
        "conv = tf.nn.conv2d(img, w, [1,2,2,1], padding='SAME')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  with tf.device(\"/gpu:0\") as dev:\n",
        "    %timeit sess.run(conv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAm_UG9RD5N2",
        "colab_type": "code",
        "outputId": "64a7883f-6369-4215-eb32-e150d8a3c64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"修改代码后，在TPU运行时下测试卷积计算速度\"\"\"\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "import timeit\n",
        "import os\n",
        "\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "tf.reset_default_graph()\n",
        "def conv_op():\n",
        "  img =  np.random.randn(128, 256, 256, 3).astype(np.float32)\n",
        "  conv_w = np.random.randn(5, 5, 3, 256).astype(np.float32)\n",
        "  conv = tf.nn.conv2d(img, conv_w, [1,2,2,1], padding='SAME')\n",
        "  \n",
        "tpu_ops = tf.contrib.tpu.batch_parallel(conv_op, [], num_shards=8)\n",
        "\n",
        "with tf.Session(tpu_address) as sess:\n",
        "  sess.run(tf.contrib.tpu.initialize_system())\n",
        "  sess.run(tpu_ops)\n",
        "  %timeit sess.run(tpu_ops)\n",
        "  sess.run(tf.contrib.tpu.shutdown_system())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 loops, best of 3: 1.82 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXcJs18i9AY7",
        "colab_type": "text"
      },
      "source": [
        "### 对比TPU和GPU运行相同神经网络所需的时间"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeDVbZWen3xM",
        "colab_type": "code",
        "outputId": "60ead964-56c6-4728-869f-ef8e40640202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1609
        }
      },
      "source": [
        "\"\"\"在TPU环境下运行\"\"\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "# 以下为第一个卷积层\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('elu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "import os\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "    )\n",
        ")\n",
        "tpu_model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "    yield x_train[offset:offset+batch_size], y_train[offset:offset + batch_size]\n",
        "    \n",
        "\n",
        "%time tpu_model.fit_generator(train_gen(1024), epochs=5, steps_per_epoch=100, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.84.68.146:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12130226390408489541)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5320787299609403774)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 9901116907118024406)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14271113716304435466)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 17747454170824028722)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7990472732005410125)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 17902030244935202217)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 16771999600873480523)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11717095653002454467)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10334245990358205316)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14608019963017080513)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13158601318287340315)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Connecting to: b'grpc://10.84.68.146:8470'\n",
            "Epoch 1/5\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(128, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input0'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='activation_1_target0')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.7602250576019287 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.0108 - sparse_categorical_accuracy: 0.7286INFO:tensorflow:New input shapes; (re-)compiling: mode=eval, [TensorSpec(shape=(128, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input0'), TensorSpec(shape=(128, 1), dtype=tf.float32, name='activation_1_target0')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.5207886695861816 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval, [TensorSpec(shape=(98, 28, 28, 1), dtype=tf.float32, name='batch_normalization_input0'), TensorSpec(shape=(98, 1), dtype=tf.float32, name='activation_1_target0')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for batch_normalization_input\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 1.4519901275634766 secs\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 1.0050 - sparse_categorical_accuracy: 0.7298 - val_loss: 1.2702 - val_sparse_categorical_accuracy: 0.6184\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.4304 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.8990 - val_sparse_categorical_accuracy: 0.6920\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 7s 68ms/step - loss: 0.3666 - sparse_categorical_accuracy: 0.8734 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.7608\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 7s 71ms/step - loss: 0.2963 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.3072 - val_sparse_categorical_accuracy: 0.8840\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 7s 72ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.9027 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.9016\n",
            "CPU times: user 7.09 s, sys: 1.37 s, total: 8.46 s\n",
            "Wall time: 44 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7effae59cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0vSo55Drlzj",
        "colab_type": "code",
        "outputId": "91377e3e-5eba-4a73-b14e-a77aab1758da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1123
        }
      },
      "source": [
        "\"\"\"在GPU环境下运行\"\"\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('elu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=1e-3, ),\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "def train_gen(batch_size):\n",
        "  while True:\n",
        "    offset = np.random.randint(0, x_train.shape[0] - batch_size)\n",
        "    yield x_train[offset:offset+batch_size], y_train[offset:offset + batch_size]\n",
        "    \n",
        "\n",
        "%time model.fit_generator(train_gen(1024), epochs=5, steps_per_epoch=100, validation_data=(x_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 3s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "100/100 [==============================] - 30s 296ms/step - loss: 1.0789 - sparse_categorical_accuracy: 0.7219 - val_loss: 1.5293 - val_sparse_categorical_accuracy: 0.5292\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.4421 - sparse_categorical_accuracy: 0.8486 - val_loss: 1.2623 - val_sparse_categorical_accuracy: 0.5931\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3585 - sparse_categorical_accuracy: 0.8746 - val_loss: 0.5929 - val_sparse_categorical_accuracy: 0.7845\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.3855 - val_sparse_categorical_accuracy: 0.8586\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2689 - sparse_categorical_accuracy: 0.9030 - val_loss: 0.3417 - val_sparse_categorical_accuracy: 0.8756\n",
            "CPU times: user 51.6 s, sys: 11.2 s, total: 1min 2s\n",
            "Wall time: 2min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f34cbc600b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}